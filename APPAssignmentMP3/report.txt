Tiled 2D Convolution

3)  Report.
    It's time to do some performance testing and analysis.  Included in the 
    MP3-convolution_block folder is a folder called "test", which contains two 
    test case input sets.  Using these test cases, and any others that you wish 
    to create to support your findings, provide answers to the following questions, 
    along with a short description of how you arrived at those answers.  

    You are free to use any timing library you like, as long as it has a reasonable 
    accuracy.  Search for the section on Timing in the CUDA C BestPractices Guide to 
    learn about how to use CUDA timing libraries. 

    Remember that kernel invocations are normally asynchronous, so if you want accurate
    timing of the kernel's running time, you need to insert a call to
    cudaDeviceSynchronize() after the kernel invocation.  

    1.  What is the measured floating-point computation rate for the CPU and GPU kernels 
    in this application?  How do they each scale with the size of the input? 


    2.  How much time is spent as an overhead cost of using the GPU for
    computation?  Consider all code executed within your host function, with
    the exception of the kernel itself, as overhead.  How does the overhead scale 
    with the size of the input?
	
	1 flops formula=matrixsizeofkernel * matrixsizeofgivenmatrix *2/totaltime;
	table for gpulab7
	flops for gpu 1024= 93622857 flops flops for cpu 655360000flops
	flops for 2048=355,449,491 flops flops for cpu   655360000flops
	flops for 4096=1,181,494,084 flops for cpu 650279689flops
	Gpu performance increases with input size.
	
	2 overheadtime
	size overhead(in secs)
	1024	0.56
	2048	0.59
	4096	0.71
	8192	1.16
	16384	2.97
	overhead increases with the size of input 